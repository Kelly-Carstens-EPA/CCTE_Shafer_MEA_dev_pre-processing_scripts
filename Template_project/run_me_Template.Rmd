---
title: "Script to pre-process MEA NFA experimental data"
author: ""
date: ""
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up

## Load libraries 

```{r}
# General packages
library(data.table)
library(openxlsx)
library(ggplot2)
library(stringi)

# Packages for parameter calculation scripts/functions
library(rhdf5) # used to create and read h5files, which is currently used as input to calculate all parameter values
library(sjemea, exclude = c('construct.s','map2list')) # original package with functions to calculate parameters. Excluding objects that will be loaded with the meadq package
library(meadq) # package with wrapper and/or modifications to several functions in sjemea
library(pracma, exclude = 'peaks') # used for MI and trapz function for AUC calculation. Excluding the 'peaks' function because we want the 'peaks function from sjemea
library(compiler) # used for MI calculation
library(gtools, exclude = 'logit') # used for MI  calculation. Excluding logit becasue conflicts with pracma package

print(sessionInfo())
```


## Project variables definitions 

```{r}
project_name <- "" # e.g. "Example2020"

spidmap_file <- "" # path to file that maps treatment names to sample IDs (optional)
spid_sheet <- '' # desired sheet in spidmap_file (can be numeric or the sheet name) (optional)

project.input.dir <- "" # main folder of experimental data for project (usually on the L drive)
scripts.dir <- "L:/Lab/NHEERL_MEA/CCTE_Shafer pre-process for TCPL/MEA_dev/CCTE_Shafer_MEA_dev_pre-processing_scripts/R" # directory containing the pre-processing scripts for the NFA
root.output.dir <- "L:/Lab/NHEERL_MEA/CCTE_Shafer pre-process for TCPL/MEA_dev/CCTE_Shafer_MEA_dev_pre-processing_projects" # main directory where the output should be saved
assay_component_map_filename <- "L:/Lab/NHEERL_MEA/CCTE_Shafer pre-process for TCPL/MEA_dev/CCTE_Shafer_MEA_dev_pre-processing_scripts/mea_nfa_component_name_map.csv"

project.output.dir <- file.path(root.output.dir, project_name)
if (!dir.exists(project.output.dir)) dir.create(project.output.dir)
```

If the scripts.dir is managed with version control, check that there are no local or uncommitted modifications, and then enter the following information to record the branch and most recent commit to the pre-processing scripts repository: 

* **branch**: <enter branch>
* **commit date**: <enter commit date>
* **commit message**: <enter commit message>
* **commit SHA**: <enter commit SHA>
* **link to scripts**: <GitHub link followed by commit SHA>

```{r}
# Source scripts containing functions that may be used throughout

# Functions to read and write files log
source(file.path(scripts.dir, 'writeFilesLog.R'))
source(file.path(scripts.dir, 'readFilesLog.R'))

objects.to.keep <- c(ls(),'objects.to.keep')
```


# Check for READMEs and other well quality notes in project folder 

Scan for txt files with notes that might affect dosing, wllq
```{r}
txt.files <- list.files(project.input.dir, pattern = '\\.txt', recursive = T, full.names = T)
```

View any README .txt files
```{r}
# Read in the READMEs
readmes.filename <- txt.files[grepl('read( )*me',tolower(txt.files))]
readmes.body <- sapply(readmes.filename, scan, what = character(), sep = '\n', quiet = T) # read the text files
readmes.body <- sapply(readmes.body, paste0, collapse = "\n") # Make each note 1 string

# If the README file only contains this generic text, then don't need to view
# (modify as needed)
generic.readme.text <- 'The following wells have been discarded from the Alamar Blue assay due to returning results outside the acceptable bounds of the assay:
X

The following wells have been discarded from the LDH assay due to returning results outside the acceptable bounds of the assay:
X'
readmes.body <- readmes.body[readmes.body != generic.readme.text]

# View the readmes that have any non-generic text
if (length(readmes.body) > 0) {
  for (i in 1:length(readmes.body)) {
    cat(i,'\n')
    cat(names(readmes.body)[i],'\n')
    cat(readmes.body[i])
    cat('\n\n')
  }
}
```


Check for any other .txt files that appear may have relevant notes

```{r}
cat(setdiff(txt.files,readmes.filename), sep = "\n")
```


# Identify source experimental and meta data files

Get the list of group folders from which you want to extract data
```{r}
group.folders <- list.files(path = project.input.dir, 
                            pattern = ".*[0-9]{8}.*", 
                            full.names = T, 
                            recursive = F)
group.folders
```

For each group folder, get the desired files (files containing cytotoxicity data, meta data, and spike list files) and save in the vector 'all.files'

```{r}
# Function to extract desired files for a given culture_datethat is organization in the standard structure
# Modify as needed for the given project
get_NFA_files_by_group <- function(group.folderi) {
  cytotox.files <- list.files(path = group.folderi, 
                              pattern = '(Calculations)|(Summary)', 
                              full.names = T)
  mfiles <- list.files(path = group.folderi,
                       pattern = 'MaestroExperimentLog',
                       full.names = T, recursive = T)
  slists <- list.files(path = group.folderi, 
                       pattern = '_spike_list\\.csv', 
                       full.names = T, recursive = T)
  filesi <- c(cytotox.files, mfiles, slists)
  return(filesi)
}

# For each culture, apply the above function to get the list of files
all.files <- c()
for (group.folderi in group.folders) {
  all.files <- c(all.files, get_NFA_files_by_group(group.folderi))
}

# Basic cleaning:
# Remove files dummy "ghost" files that contain "~$" in the file name
all.files <- Filter(function(filei) !grepl('\\Q~$\\E',filei), all.files)
# Remove files that contain the word "deprecated" anywhere in the file name
all.files <- Filter(function(filei) !grepl('deprecated',tolower(filei)), all.files)

# Additional filters as needed:

# Total number of files
length(all.files)
```

Check for the expected number of files per group

```{r}
for (group.folder in group.folders) {
  cat("\n\n",group.folder,"\n",sep = "")
  group.folder <- sub("\\(","\\\\(",group.folder)
  group.folder <- sub("\\)","\\\\)",group.folder)
  group.folder.files <- grep(group.folder, all.files, fixed = T, val = T)
  
  cat("Calculations/Summary files: ")
  cat(sum(grepl("(Calculations)|(Summary)",group.folder.files)))
  cat(' (',paste0(basename(grep("(Calculations)|(Summary)",group.folder.files, val = T)),collapse = ", "),')\n')
  
  cat("Number of MaestroExperimentLog files: ")
  cat(sum(grepl("MaestroExperimentLog",group.folder.files)),"\n")
  
  cat("Number of spike list files: ")
  cat(sum(grepl("_spike_list",group.folder.files)),"\n")
  
}
```

Save a log of the selected source files for reference

```{r}
writeFilesLog(all.files, files.log.dir = project.output.dir, project_name = project_name)
rm(list = setdiff(ls(), objects.to.keep))
```



# Extract raw data & calculate features

Functions to source:

```{r}
# spike list to h5 conversion scripts
source(file.path(scripts.dir, 'spike_list_functions.R'))
source(file.path(scripts.dir, 'h5_conversion.R'))

# scripts to calculate the first 16 parameters
source(file.path(scripts.dir,'create_ont_csv.R'))
source(file.path(scripts.dir,'create_burst_ont_Data.R'))
source(file.path(scripts.dir,'local.corr.all.ont.ae.filter.R'))

# normalized mutual information
source(file.path(scripts.dir,'spikeLoadRoutines.R'))
source(file.path(scripts.dir,'nmi2_final.R'))
source(file.path(scripts.dir,'nmi_wrapper.R'))
source(file.path(scripts.dir,'MI_script_all.R'))

# AUC
source(file.path(scripts.dir,'prepare_parameter_values.R'))
source(file.path(scripts.dir,'linear_interpolate_DIV.R'))
source(file.path(scripts.dir,'add_wllq_by_well.R'))
source(file.path(scripts.dir,'parameter_values_to_AUC.R'))

# Extracting the cytotoxicity data
source(file.path(scripts.dir,'run_cytotox_functions.R'))
source(file.path(scripts.dir,'createCytoTable2.R'))
source(file.path(scripts.dir,'createCytoData.R'))
```

**Convert spike list files to h5 files**
```{r}
h5_conversion(project.output.dir, 
              files.log.output.dir = project.output.dir,
              remake_all = FALSE, 
              check_nwells_per_plate = 48, 
              recording_duration_sec = 900.00)
```

**Calculate 16 parameter values with meadq/sjemea functions**

```{r}
create_ont_csv(project.output.dir, 
               remake_all = FALSE,
               get_h5Files_under_project.output.dir = TRUE)
```

**Calculate the normalized mutual information parameter**

```{r}
run_mi_functions(project.output.dir, 
                 get_h5Files_under_project.output.dir = TRUE, 
                 remake_all = FALSE)
```

**Calculate Area-Under-the-Curve values**

Combine all parameter data files, update well quality by well, add dummy points at DIV 2, and check for non-standard DIV.
```{r}
# Get paths to the parameter data files & wllq table
div_data_file_folders <- file.path(project.output.dir,c('prepared_data','All_MI'))
div_data_files <- unlist(lapply(div_data_file_folders, list.files, 
                                pattern = '.csv$', 
                                full.names = TRUE, 
                                recursive = FALSE))
wllq.tb.by.well.file <- file.path(project.output.dir, 
                                  paste0(project_name,'_well_quality_table_by_well.csv'))

# Run the function
prepare_parameter_values(project.output.dir, 
                         project_name, 
                         div_data_files = div_data_files,
                         id.columns = c("date","Plate.SN","DIV","well","trt","dose","units","file.name"),
                         wllq.tb.by.well.file = wllq.tb.by.well.file,
                         num_rows_per_plate = 6,
                         num_columns_per_plate = 8,
                         expected_DIVs = c(5,7,9,12),
                         add_DIV2_values_of_0 = TRUE,
                         interpolate_stnd_DIVs = TRUE)
```

Calculate the trapezoidal area under the curve for each parameter for each well versus the DIV

```{r}
# Get single DIV data file created with prepare_parameter_values()
div_data_file <- file.path(project.output.dir,'output',paste0(project_name,'_parameters_by_DIV.csv'))

# Run the function
parameter_values_to_AUC(project.output.dir, 
                        project_name, 
                        div_data_file = div_data_file,
                        id.columns = c("date","Plate.SN","DIV","well","trt","dose","units","file.name","wllq_by_well","wllq_notes_by_well","wllq_ref_by_well"),
                        expected_DIVs = c(2,5,7,9,12),
                        dose_column_name = 'dose')
```

**Extract the cytoxicity data**

```{r}
# Get the well quality table
wllq.tb.by.well.file <- file.path(project.output.dir, 
                                  paste0(project_name,'_well_quality_table_by_well.csv'))

# Run function to read from Calculations files
run_cytotox_functions(project.output.dir, project_name, 
                      get_files_from_log = TRUE, 
                      wllq.tb.by.well.file = wllq.tb.by.well.file)
```


# Prepare the level 0 table

Remove extra objects from environment

```{r}
rm(list = setdiff(ls(),objects.to.keep))
```

Read in the files under the "output" folder (_parameters_by_DIV, _AUC, _cytotox), convert to long-format (1 row per parameter), and combine into 1 table.

```{r}
source(file.path(scripts.dir, 'tcpl_MEA_dev_AUC.R'))
id.columns <- c("date","Plate.SN","DIV","well","trt","dose",                "units","file.name","wllq_by_well","wllq_notes_by_well","wllq_ref_by_well")

# Run the function and get a single table (dat)
dat <- tcpl_MEA_dev_AUC(project.output.dir, 
                        project_name, 
                        assay_component_map_filename,
                        id.columns = id.columns)

```

Initialize columns that will be useful for checks below

```{r}
# Define the full well id to faciliate checking
dat[, full_well_id := paste(apid, rowi, coli, sep = '_')]

# Get the culture_datedate from the apid
dat[, culture_date := stri_extract(apid, regex = '[0-9]{8}')]

dat[, acnm_short := sub("CCTE_Shafer_MEA_dev_","",acnm)]
```


# Check treatment labels

```{r}
# save the original treatment name as read from the source file (srcf) for reference
dat[, treatment_srcf := treatment]
```

* Check for any missing treatment labels. Usually, any NAs would correspond to blank or Media-only wells, but confirm there are no unexpected NA treatments.

```{r}
dat[is.na(treatment)]
# dat[is.na(treatment), treatment := 'Media']
```

* Standardize the treatment label for vehicle control wells (usually indicated by conc == 0)

```{r}
# # Example: check the treatment labels wherever the conc == 0
dat[conc == 0, .N, by = .(treatment)][order(-N)]

# If DMSO was used as the vehicle control in every plate and is not currently labelled, update all to DMSO
# (sometimes may use Water or EtOH instead)
# dat[conc == 0, treatment := 'DMSO']

# Check that all wells in column 2 are vehicle controls
dat[coli == 2, .N, by = .(treatment, conc)]

# Check that all vehicle controls are in column 2
dat[treatment == 'DMSO', .N, by = .(coli)]
```

* There should only be 1 treatment per well (apid + rowi + coli). If there are multiple, that means that some parameter values are showing different treatments for the given well (usually due to e.g., a different treatment label for the Cytotoxicity data than in the MaestroExperiment Log). It is possible that the arrangement of the treatments in the LDH and AB plates was different than the MEA plates, but this is rare. Resolve any discrepancies.

```{r}
dat[, .(num_treatments_per_well = length(unique(treatment))), by = .(apid, rowi, coli)][num_treatments_per_well > 1]

# Example check for wells that are associated with multiple treatments
# check.wells <- dat[, .(num_treatments_per_well = length(unique(treatment))), by = .(full_well_id)][num_treatments_per_well > 1, unique(full_well_id)]
# dat[full_well_id %in% check.wells, .N, by = .(apid, treatment, rowi, srcf)]
# Refer to lab notebook or other data sources to determine which treatment is correct (or if the treatments should be different for different parameters). Update source data files if any typo-s are found.
```

* Check the number of treatments per plate. Usually, there should be 7 unique treatments per MEA plate (6 chemicals + vehicle control). If there are more or less than 7, check for any typos.

```{r}
dat[, .(num_treatments_per_plate = length(unique(treatment))), by = .(apid)][num_treatments_per_plate != 7]
```

* Check for the expected number of wells associated with each treatment. Usually, for every treatment, there should be 3 plates * 7 wells per plate = 21 wells. If there are more or less than 21 wells, check for any typos in the treatment. Note that vehicle controls will be associated with 6 wells * number of plates. Some treatments may have been intentionally repeated in multiple cultures (in which case these will be associated with a multiple of 21 wells). Check that the treatments that are associated with multiple cultures appear are not unexpected). 

```{r}
dat[, .(num_wells_per_treatment = length(unique(full_well_id))), 
    by = .(treatment)][num_wells_per_treatment != 21]

# Check that treatments that appear to have been repeated were tested in a group that indicates an intentional repeat (rather than a typo)
# check.treatments <- dat[, .(num_wells_per_treatment = length(unique(full_well_id))), by = .(treatment)][num_wells_per_treatment != 21 & !treatment %in% c('DMSO','Water','EtOH'), unique(treatment)]
# check.treatments
# dat[treatment %in% check.treatments, 
#     .(cultures = paste0(sort(unique(culture_date)),collapse = ",")), 
#     by = .(treatment)]
```


# Prepare columns needed for TCPL lvl0 table

## apid

Placeholder to update this in the future if we want to do something more sophisticated than the current apid's created in `tcpl_MEA_dev_AUC()` (e.g., including the project name?)

## srcf

Placeholder to update this in the future if we want to do something more sophisticated than what is currently done in `tcpl_MEA_dev_AUC()` (e.g., reference .zip folders that contain ALL source files, include meta + raw data?)

## spids 

Map the treatment names to the sample IDs using the spidmap file. The spidmap data table should be made to contain the following 4 columns:

* treatment = treatment names as they appear in the `dat`
* spid = the sample ID (registered in ChemTrack). There should be a clear, 1-to-1 mapping between every treatment name and spid. The spids usually begin with a prefix such as “EPA”,“EX”, “TP” or “TX” followed by a 6-8 digit code.
* stock_conc = stock concentration
* stock_conc_unit = units of the stock concentration

```{r}
spidmap <- as.data.table(read.xlsx(spidmap_file, sheet = spid_sheet))
head(spidmap)

# Add the file name
spidmap[, 'spidmap_file' := basename(spidmap_file)]


# Identify the column in the spidmap that contains the sample IDs and rename as "spid" 

# Example:
# setnames(spidmap, old = 'EPA_SAMPLE_ID', new = 'spid')


# Identify and/or create the column in the spidmap that corresponds to the treatment names in dat (and make this column character)
# Talk to lab technicians is not sure

# Example:
# spidmap[, treatment := as.character(paste0('7126 ',Plate.Position))]


# Identify and rename the column in spidmap that contains the stock concentration. Confirm that the stock concentration contains a numeric value.

# Example:
# spidmap[, stock_conc_char := `Conc..(mM)`]
# spidmap[, stock_conc := stri_extract(stock_conc_char, regex = '[0-9]*(\\.)*[0-9]*')]
# spidmap[, stock_conc := as.numeric(stock_conc)]
spidmap[is.na(stock_conc)] # check no NAs


# Determine the units of the stock concentrations

# Example:
# The stock conc column in spidmap is named 'Conc..(mM)'
# Thus, the stock concentration units are in 'mM'
spidmap[, stock_conc_unit := 'mM']


# View the spidmap, determine if any additional cleaning is needed
View(spidmap)

# Cleanings for this specific spidmap:
spidmap <- spidmap[!is.na(`Conc..(mM)`)]

# Check that all test treatments in dat are covered by the spidmap
# (vehicle controls won't have spid's, and that is okay)
setdiff(dat$treatment, spidmap$treatment)

# Add additional spidmaps if needed
# Then rbind into 1 spidmap

# Recheck all treatments covered:
setdiff(dat$treatment, spidmap$treatment)


# Check that all treatments in the spidmap are present in the dat
setdiff(spidmap$treatment, dat$treatment)
# Should be empty IF all treatments in the spidmap are expected to have been tested in this assay


# Check if every treatment name maps to 1 unique sample ID in spidmap
spidmap[treatment %in% unique(dat$treatment), .N, by = .(treatment)][N > 1]

# Check if every sample ID in spidmap maps to 1 unique treatment
spidmap[treatment %in% unique(dat$treatment), .N, by = .(spid)][N > 1]


# Merge the spidmap and dat
dat <- merge(dat, spidmap[, .(treatment, spid, stock_conc, stock_conc_unit, spidmap_file)],
             by = 'treatment', all.x = T)


# For controls that do not have a spid, the treatment name can be used as the spid
dat[is.na(spid), spid := treatment]
stopifnot(nrow(dat[is.na(spid)]) == 0)
```


## wllt (well type)

Define the well type (for the ToxCast Pipeline)

* 't' = treated/test well
* 'n' = neutral/negative control
* 'b' = blank
* 'p' = positive control

Not all well types will be present for every assay/experiment. Other wllt definitions are also available (refer to TCPL documentation).

Note that only treatments with wllt == 't' will be fit to a dose response curve and need to have a registered sample ID.

```{r}
dat[!is.na(spidmap_file), wllt := 't'] # initialize default
dat[spid %in% c('DMSO','Water','EtOH'), wllt := 'n'] # neutral controls
dat[spid %in% c('Media','Blank'), wllt := 'b'] # blank

# Check any remaining cases
dat[is.na(wllt), .N, by = .(spid, treatment, spidmap_file)]

# Assign wllt for any remaining treatments


# View treatments in all non-test wells
dat[wllt != 't', .N, by = .(wllt, spid)]
stopifnot(nrow(dat[is.na(wllt)]) == 0)
```

Check for expected # of vehicle control wells per plate (usually there should be 6 per plate)

```{r}
dat[, .(num_control_wells_per_plate = length(unique(full_well_id[wllt == 'n']))),
    by = .(apid)][num_control_wells_per_plate != 6]
```

# Check concentrations and units

## Preliminary conc checks

```{r}
# save original concentration from source data files for reference
dat[, conc_srcf := conc]
dat[, conc := as.numeric(conc)]

# confirm concentration is defined for every row
stopifnot(nrow(dat[is.na(conc)]) == 0)

# Confirm no cases where conc == 0 for test wells
stopifnot(nrow(dat[wllt == 't' & conc == 0]) == 0)
```

## Compare conc's with expected conc based on stock conc & conc index

```{r}
dat[, conc_log10 := log10(conc)]

# Define the concentration index (cndx)
# Note that the cndx is specific to each plate (apid).
# Also note that TCPL also includes the wllt and some additional columns in the 'by' argument for the cndx definition. This cndx in just for our purposes of concentration-checking
dat[, cndx := frank(conc, ties.method = 'dense'), 
    by = .(spid, apid, acnm)]
```

Calculate expected concentration (my anticipated conc) based on stock concentration and dilution scheme
```{r}
# Default dilution scheme from the stock concentration shown below for each concentration index 
# Modify as needed for a given project
# See e.g., formulas in "Dosing Prep" Calculations file for the dosing scheme.
# Note that the top concentration in mM from the spidmap is usually the top concentration in uM in the MEA plate.
# If the the scheme is different for a few substances,
# update dilution_factor for individual treatments after merge with dat
dilution.tb <- data.table(cndx = 7:1)
dilution.tb[cndx == 7, dilution_cndx_multiplier := 1]
dilution.tb[cndx == 6, dilution_cndx_multiplier := 15/(35+15)]
dilution.tb[cndx == 5, dilution_cndx_multiplier := 15/(30+15)]
dilution.tb[cndx == 4, dilution_cndx_multiplier := 15/(35+15)]
dilution.tb[cndx == 3, dilution_cndx_multiplier := 15/(30+15)]
dilution.tb[cndx == 2, dilution_cndx_multiplier := 15/(35+15)]
dilution.tb[cndx == 1, dilution_cndx_multiplier := 15/(30+15)]
dilution.tb[, dilution_factor := Reduce(f = `*`, dilution_cndx_multiplier, accumulate = TRUE)]
dilution.tb

# Merge in dilution scheme with dat
dat <- merge(dat, dilution.tb, by = 'cndx', all.x = T)

# Calculate my anticipated concentrations based on dilutions and stock_conc
dat[, top_conc := as.numeric(stock_conc)] # for most treatments, can assume top_conc (in uM) is equal to the stock_conc (in mM).
dat[, my_anticipated_conc := top_conc*dilution_factor]
dat[, my_anticipated_conc_log10 := log10(my_anticipated_conc)]
```

In Carstens et al., 2022, the AC50s from replicates in the NFA were found to vary by approximately +/- 0.5 log10 uM. Therefore, I think that any variability in the concentrations due to differences in data processing of decimal places/rounding/stock concentrations in different input files is negligible if it is less that 0.005 log10-uM (2 orders of magnitude lower).

Check for any cases where the conc from the srcf and my_anticipated_conc disagree by more than +/-0.005 log10-uM

```{r}
# Check for any cases where the conc from the srcf and my_anticipated_conc disagree by more than +/-0.005 log10-uM
dat[, conc_log10_diff_abs := abs(conc_log10 - my_anticipated_conc_log10)]
dat[conc_log10_diff_abs >= 0.005, .N, 
    by = .(treatment, stock_conc, cndx, conc, my_anticipated_conc, conc_log10_diff_abs, culture_date)][order(treatment, conc)]


# Possible reasons for disagreement between conc and my anticipated conc:
# - conc's in source file were not corrected to stock_conc
# - conc's in source file were "corrected" to the wrong stock_conc
# - stock_conc in spidmap_files are off (so my_anticipated_conc is off). This is unlikely.
# - treatment was intentionally tested at a different series than what is defined in dilution.tb (so my_anticipated_conc is off)
# - something else is off with the conc-data alignment


```

Take appropriate action for each of the discrepancies identified
```{r}

```


Re-check conc's after updates
```{r}
dat[, my_anticipated_conc := top_conc*dilution_factor]
dat[, my_anticipated_conc_log10 := log10(my_anticipated_conc)]
dat[, conc_log10_diff_abs := abs(conc_log10 - my_anticipated_conc_log10)]
dat[conc_log10_diff_abs >= 0.005, .N, 
    by = .(treatment, stock_conc, cndx, conc, my_anticipated_conc, conc_log10_diff_abs, culture_date)][order(treatment, conc)]
```

If no conc's differ from my_anticipated_conc by more than 0.005 OR my_anticipated_conc is known to be the correct concentration tested, set all conc's to my_anticipated_conc for consistency

```{r}
dat[, conc := my_anticipated_conc]
```

Confirm that the concentration for a given well is consistent (i.e., is the same for all parameters)

```{r}
dat[, .(num_concs_per_well = length(unique(conc))), by = .(full_well_id)][num_concs_per_well > 1]
```

Confirm that there are the expected number of concentrations tested per treatment

```{r}
# For single-concentration screening check that there is 1 concentration tested per spid
# dat[wllt == 't', .(num_conc_tested = length(unique(conc))), by = .(spid)][num_conc_tested != 1]

# For multi-concentration screening, there should be 7 concentrations per sample (unless the sample was intentionally screened at different doses in different cultures)
dat[wllt == 't', .(num_conc_tested = length(unique(conc))), by = .(spid, treatment)][num_conc_tested != 7]
```

Update the concentration index

```{r}
dat[, cndx := frank(conc, ties.method = 'dense'), 
    by = .(spid, apid, acnm)]
```



## Determine concentration for non-test wells

```{r}
# View current concentrations
dat[wllt != 't', .N, by = .(spid, conc, treatment)]

# For DMSO, can assume concentration is 0.1% unless otherwise noted
dat[spid == 'DMSO', conc := 0.1]

# conc for Media/Blank can be NA
dat[spid %in% c('Media','Blank'), conc := NA_real_]
```


## Concentration units 

```{r}
# View units that have already been defined
dat[, .N, by = .(wllt, units, stock_conc_unit)]
```

The vast majority of treatments will be in uM. Note that the units are not currently saved with the cytotoxicity data in the Calculations files, so those data rows will currently be NA. For the MEA data, the units are taken from the meta-data "Log" table (previously called the MaestroExperiment Log). However, sometimes this column may not have been updated for a given group, so use your best judgement if the units are not actually in uM. Use the stock conc units to help verify.

```{r}
# For vehicle control wells, units are '%'
dat[spid == 'DMSO', units := '%']

# Confirm there is currently 1 unit type per treatment
dat[, .(num_units_per_spid = length(unique(units[!is.na(units)]))), by = .(spid, treatment)][num_units_per_spid > 1]

# For test wells, if the stock_conc_unit are mM, then the units for the MEA and cytotoxicity data are usually uM (micromolar)
dat[wllt == 't' & stock_conc_unit == 'mM', units := 'uM']

# Sometimes, the units may not be in a molar value.
# For example, if the stock conc is in mg/mL, then the test units are likely in ug/mL
# If the molecular weight is known, convert these values to uM. 
# Otherwise, note the actual units

# View updated units
dat[, .N, by = .(wllt, units, stock_conc_unit)]
```


# Finalize well quality

## Add wllq by treatment, cndx, and culture date

```{r}
wllq.tb.by.trt.file <- file.path(project.output.dir,                                   paste0(project_name,'_well_quality_table_by_treatment_cndx_culture_date.csv'))

# define the "assay" for every row of dat
dat[grepl("LDH",acnm), assay := 'LDH']
dat[grepl("AB",acnm), assay := 'AB']
dat[is.na(assay), assay := 'NFA']

# Source function
source(file.path(scripts.dir, 'add_wllq_by_treatment_cndx_culture_date.R'))

# Run function to update well quality 
dat <- add_wllq_by_treatment_cndx_culture_date(dat, wllq.tb.by.trt.file)

```

## Merge all wllq columns

```{r}
# Take the minimum wllq across all wllq columns
dat[, wllq := pmin(wllq_by_well, wllq_by_trt, na.rm = T)]

# Merge wllq notes and ref
dat[, wllq_notes := paste0(ifelse(is.na(wllq_notes_by_well), '', wllq_notes_by_well),
                           '; ',
                           ifelse(is.na(wllq_notes_by_trt), '', wllq_notes_by_trt))]
dat[, wllq_ref := paste0(ifelse(is.na(wllq_ref_by_well), '', wllq_ref_by_well),
                         '; ',
                         ifelse(is.na(wllq_ref_by_trt), '', wllq_ref_by_trt))]
# remove leading "; "
dat[, wllq_notes := sub('^; ','',wllq_notes)]
dat[, wllq_ref := sub('^; ','',wllq_ref)]
```

Confirm that the wllq and notes appear as expected

```{r}
View(dat[, .N, by = .(wllq, wllq_notes, wllq_ref)][order(wllq)])
```


# Note the vehicle controls per plate

Check if any plates have multiple vehicle controls

```{r}
# Check if any plates have multiple vehicle controls
# (if multiple are present on a given plate, consider the normalization method and/or apid definition for the given plate)
dat[, num_vehicle_control_types_per_plate := length(unique(treatment[wllt == 'n'])), by = .(apid)]
dat[num_vehicle_control_types_per_plate > 1]

# View the vehicle controls on these plates
# dat[num_vehicle_control_types_per_plate > 1 & wllt == 'n', .N, by = .(apid, treatment, spid)]
```


# Check for NA rvals

Check for any NA or infinite rvals where wllq == 1. In the ToxCast pipeline, any NA rval will be set to wllq = 0 (at level 2).

Check for NA's in all parameters other than the 'DIV' parameters.
In these cases, if there are any NA rvals with wllq == 1, that indicates there was a problem in the data files, data collection, and/or pre-processing. These instances warrant further investigations
```{r}
dat[(is.na(rval) | is.infinite(rval)) & wllq == 1 & !grepl('DIV',acnm), .N, by = .(acnm)]
stopifnot(nrow(dat[is.na(rval) & wllq == 1 & !grepl('DIV',acnm)]) == 0)
```

Note NA's in the DIV-specific parameters. These can be left as NA, but just note the occurrence
```{r}
dat[(is.na(rval) | is.infinite(rval)) & wllq == 1 & grepl('DIV',acnm), .N, by = .(acnm)]
```

# For repeated treatments, determine which culture(s) to keep

Sometimes a treatment is repeated in multiple cultures within a project. This is usually due to some unwanted results in the first culture, e.g., high variability, precipitate, or cytotoxicity. In any case, discuss with lab which culture(s) we want to keep for each repeated treatment. Make graphs to visualize as needed. For cultures that we don't want to keep for a given treatment, set wllq := 0 and add a wllq_note.

```{r}
# define the "assay" for every row of dat
dat[grepl("LDH",acnm), assay := 'LDH']
dat[grepl("AB",acnm), assay := 'AB']
dat[is.na(assay), assay := 'NFA']

# Identify treatments tested in multiple cultures for a given assay
dat[wllq == 1 & wllt == 't', .(num_cultures = length(unique(culture_date)),
                               cultures = paste0(sort(unique(culture_date)),collapse = ",")),
    by = .(treatment, assay)][num_cultures > 1]
```

# Confirm every treatment has some data with wllq=1

```{r}
all.treatments <- dat[wllt == 't', unique(treatment)]
dat[wllq == '1', setdiff(all.treatments, treatment)]
```

# Check for the expected number of technical replicates for every treatment-conc 

Usually there are 3 technical replicates, unless the treatment was intentionally repeated. Again, this check serves to check for potential typos

```{r}
dat[wllt == 't', 
    .(num_replicates = length(unique(full_well_id))), by = .(treatment, spid, conc)][num_replicates != 3]
```


# Data usability checks

Set wllq to 0 for apid where the activity in control wells is very low (specifically where the median of controls on DIV 12 is < 10 spikes per min or < 2 active electrodes).
```{r}
# Plates with MFR < 10 spikes per minute on DIV 12
apid.low.mfr <- dat[wllq == 1 & wllt == 'n' & grepl("firing_rate_mean_DIV12",acnm),
                    .(bval = median(rval, na.rm = T)), 
                    by = .(apid)][bval < 10/60, unique(apid)]

# Plates with < 2 active electrodes on DIV 12
apid.low.ae <- dat[wllq == 1 & wllt == 'n' & grepl("active_electrodes_number_DIV12",acnm), 
                   .(bval = median(rval, na.rm = T)), 
                   by = .(apid)][bval < 2, unique(apid)]

# View affected plates
exclude.apid <- union(apid.low.mfr, apid.low.ae)
cat('Plates with very low activity on DIV 12 for control wells: ')
print(dat[apid %in% exclude.apid & (grepl("active_electrodes_number_DIV12",acnm) | grepl("firing_rate_mean_DIV12",acnm)) & wllt == "n", 
          .(apid, acnm_short, rval)])

# Set wllq to 0 for affected plates
dat[apid %in% exclude.apid, `:=`(wllq = 0,
                                 wllq_notes = paste0("Controls low activity on DIV 12 (median MFR < 10 spikes per min or nAE < 2); ",wllq_notes))]


```


# Data summaries 

```{r}
dat[, acnm_short := sub("CCTE_Shafer_MEA_dev_","",acnm)]
```

## Counts 

**Number of cultures dates:**

```{r}
dat[, length(unique(sub("_.+$","",apid)))]
```

**Range of culture dates:***
```{r}
dat[, range(sub("_.+$","",apid))]
```

**Number of plates tested:**
```{r}
dat[, length(unique(apid))]
```

**Number of compounds tested:**
```{r}
dat[wllt == "t", length(unique(spid))]
```

**Wllq counts for all data points:**
```{r}
print(dat[, .N, by = "wllq"]) # note if wllq is NA anywhere
```

**Number of unique assay components present:**
(there should be 2 cyto + 17 AUC + 4*17 DIV = 87)
```{r}
length(unique(dat$acnm))
```

**Any plates don't have 48 wells for each component?** 
```{r}
dat[, .N, by = .(apid, acnm)][N != 48]
```

**Any plates don't have 6 control wells for each component?**
```{r}
print(dat[wllt == "n", .N, by = c("acnm","apid")][N != 6])
```

**Range of assay component values**
```{r}
dat[wllq == 1, .(min = format(min(rval,na.rm=T),digits=2,scientific = F), 
                 median = format(median(rval,na.rm=T),digits=2,scientific = F),
                 max = format(max(rval,na.rm=T),digits=2,scientific = F),
                 num_NA = sum(is.na(rval))), by = .(acnm_short)][order(acnm_short)]
```

## Visualizations

The goal here is to get your eyes on the data visually and to prepare summaries to share with the lab. This section could definitely use a facelift (e.g., update to ggplot2 instead of base R plots, consider which plots are most informative to share with lab technicians).

```{r}
# view all by plate
stripchart(rval ~ sub("_","\n",apid), dat[wllq == 1 & wllt == "t" & acnm == "CCTE_Shafer_MEA_dev_firing_rate_mean_DIV12"], vertical = T, pch = 1, method = "jitter", las = 2, cex.axis = 0.75,
           col = "cornflowerblue", main = paste0(project_name," NFA Mean Firing Rate DIV12 by Plate"))
stripchart(rval ~ sub("_","\n",apid), dat[wllq == 1 & wllt == "n" & acnm == "CCTE_Shafer_MEA_dev_firing_rate_mean_DIV12"], vertical = T, pch = 19, method = "jitter", las = 2, cex.axis = 0.75,
           add = T)
legend(x = "topright", legend = c("control","all treated"), col = c("black","cornflowerblue"), pch = c(19,1), bg = "transparent")

stripchart(rval ~ sub("_","\n",apid), dat[wllq == 1 & wllt == "t" & acnm == "CCTE_Shafer_MEA_dev_firing_rate_mean"], vertical = T, pch = 1, method = "jitter", las = 2, cex.axis = 0.75,
           col = "cornflowerblue", main = paste0(project_name," NFA Mean Firing Rate AUC by Plate"))
stripchart(rval ~ sub("_","\n",apid), dat[wllq == 1 & wllt == "n" & acnm == "CCTE_Shafer_MEA_dev_firing_rate_mean"], vertical = T, pch = 19, method = "jitter", las = 2, cex.axis = 0.75,
           add = T)
legend(x = "topright", legend = c("control","all treated"), col = c("black","cornflowerblue"), pch = c(19,1), bg = "transparent")

stripchart(rval ~ sub("_","\n",apid), dat[wllq == 1 & wllt == "t" & acnm == "CCTE_Shafer_MEA_dev_active_electrodes_number_DIV12"], vertical = T, pch = 1, method = "jitter", las = 2, cex.axis = 0.75,
           col = "cornflowerblue", main = paste0(project_name," NFA # Active Electrodes DIV12 by Plate"))
stripchart(rval ~ sub("_","\n",apid), dat[wllq == 1 & wllt == "n" & acnm == "CCTE_Shafer_MEA_dev_active_electrodes_number_DIV12"], vertical = T, pch = 19, method = "jitter", las = 2, cex.axis = 0.75,
           add = T)
legend(x = "topright", legend = c("control","all treated"), col = c("black","cornflowerblue"), pch = c(19,1), bg = "transparent")

stripchart(rval ~ sub("_","\n",apid), dat[wllq == 1 & wllt == "t" & acnm == "CCTE_Shafer_MEA_dev_active_electrodes_number"], vertical = T, pch = 1, method = "jitter", las = 2, cex.axis = 0.75,
           col = "cornflowerblue", main = paste0(project_name," NFA # Active Electrodes AUC by Plate"))
stripchart(rval ~ sub("_","\n",apid), dat[wllq == 1 & wllt == "n" & acnm == "CCTE_Shafer_MEA_dev_active_electrodes_number"], vertical = T, pch = 19, method = "jitter", las = 2, cex.axis = 0.75,
           add = T)
legend(x = "topright", legend = c("control","all treated"), col = c("black","cornflowerblue"), pch = c(19,1), bg = "transparent")

# define 'plotdat' - of the AUC MFR, with specialized conc group labels
plotdat <- dat[acnm == "CCTE_Shafer_MEA_dev_firing_rate_mean"]
plotdat[, conc_grp := ifelse(wllt == "n",paste0(treatment,"\n",conc),signif(conc,1))]
conc_grps <- unique(plotdat$conc_grp)
plotdat$conc_grp <- factor(plotdat$conc_grp, levels = c(grep("\n",conc_grps,val = T),sort(unique(as.numeric(conc_grps[!grepl("\n",conc_grps)])))), ordered = T)

# view all compounds together by dose
stripchart(rval ~ conc_grp, plotdat[wllq == 1], vertical = T, pch = 1, method = "jitter", las = 2,
           main = paste0("Mean Firing Rate AUC by dose for all compounds in ",project_name), ylab = "CCTE_Shafer_MEA_dev_firing_rate_mean (AUC)", xlab = "conc")
if (plotdat[, any(wllq==0)])
  stripchart(rval ~ conc_grp, plotdat[wllq == 0], vertical = T, pch = 1, method = "jitter",
             add = T, col = "red")
legend(x = "topright", legend = c("wllq==1","wllq==0"), col = c("black","red"), pch = c(1,1), bg = "transparent")

# find a compound that is likely to be a positive and plot dose response
dat[, max_conc_by_spid := as.character(max(conc)), by = .(spid)]
plot_spid <- dat[as.character(conc) == max_conc_by_spid & acnm == "CCTE_Shafer_MEA_dev_firing_rate_mean", .(med_rval = median(rval)), by = "spid"][med_rval == min(med_rval), spid[1]]
plot_plates <- dat[spid == plot_spid, unique(apid)]
stripchart(rval ~ conc_grp, plotdat[apid %in% plot_plates & (spid == plot_spid | wllt == "n") & wllq == 1], vertical = T, pch = 19, las = 2,
           col = rgb(0.1,0.1,0.1,0.5),
           ylim = range(dat[wllq == 1 & acnm == "CCTE_Shafer_MEA_dev_firing_rate_mean",rval]), ylab = "CCTE_Shafer_MEA_dev_firing_rate_mean (AUC)",
           xlab = "conc", main = paste0("Example Down Response:\n",dat[spid == plot_spid,unique(treatment)]," Mean Firing Rate AUC Dose Response"))
if (plotdat[apid %in% plot_plates & (spid == plot_spid | wllt == "n"), any(wllq==0)])
  stripchart(rval ~ conc_grp, plotdat[apid %in% plot_plates & (spid == plot_spid | wllt == "n") & wllq == 0], vertical = T, pch = 19, las = 2,
             add = TRUE, col = rgb(0.9,0,0,0.5))
legend(x = "topright", legend = c("wllq==1","wllq==0"), col = c(rgb(0.1,0.1,0.1,0.5),rgb(0.9,0,0,0.5)), pch = c(19,19), bg = "transparent")

# Cytotox
plotdat <- dat[grepl("(LDH)|(AB)",acnm)]
plotdat[, conc_grp := ifelse(wllt == "n",paste0(treatment,"\n",conc),signif(conc,1))]
conc_grps <- unique(plotdat$conc_grp)
plotdat$conc_grp <- factor(plotdat$conc_grp, levels = c(grep("\n",conc_grps,val = T),sort(unique(as.numeric(conc_grps[!grepl("\n",conc_grps)])))), ordered = T)
stripchart(rval ~ conc_grp, plotdat[wllq == 1 & grepl("AB",acnm)], las = 2,
           vertical = TRUE, pch = 1, method = "jitter", xlab = "conc", main = paste0("AB Blank-Corrected Values for ",project_name,"\nwhere wllq == 1"))
if (nrow(plotdat[wllq == 1 & grepl("LDH",acnm)]) > 0) {
  stripchart(rval ~ conc_grp, plotdat[wllq == 1 & grepl("LDH",acnm)], las = 2,
             vertical = TRUE, pch = 1, method = "jitter", xlab = "conc", main = paste0("LDH Blank-Corrected Values for ",project_name,"\nwhere wllq == 1"))
}
```



# Save final table 

```{r}
# Note that the cndx here is different than the cndx applied in tcpl
setnames(dat, old = 'cndx', new = 'cndx_pre_pro')

# Select columns to save
keep.columns <- c(
  
  # Columns needed for tcpl lvl0
  'acnm','apid', 'rowi', 'coli', 'conc','rval','srcf','spid','wllt','wllq', 

  # Additional columns for our documentation
  'acsn',  
  'treatment', 'treatment_srcf','spidmap_file',
  'cndx_pre_pro','conc_srcf', 'units',  'stock_conc', 'stock_conc_unit',
  'wllq_notes', 'wllq_ref'
)
dat <- dat[, .SD, .SDcols = keep.columns]

# Save the file
setkey(dat, NULL) # remove keys to make the file smaller
# optional character string to save with file, modify as appropriate
# nfa.dat.description <- paste0(project_name,' MEA NFA pre-processed data
# Date prepared: ',as.character.Date(Sys.Date()),
# '\nTo do before tcplWriteLvl0:
# * Exclude acnms that are for a specific DIV (see where grepl("_DIV",acnm))
# * Check that none of the data has been pipelined before (i.e., merge with current level 0 data and check for duplicates by apid, rowi, coli, and acnm)')
cat(nfa.dat.description)
save(dat, nfa.dat.description, 
     file = file.path(root.output.dir, project_name, "output", paste0(project_name,"_NFA_for_tcpl_lvl0.RData")))
```

You made it!